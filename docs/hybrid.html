<!DOCTYPE HTML>
<html>
<head>
    <title>Wayverb - Hybrid</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="/wayverb/assets/favicon.ico" />
	<!--[if lte IE 8]><script src="/wayverb/assets/js/ie/html5shiv.js"></script><![endif]-->
	<link rel="stylesheet" href="/wayverb/assets/css/main.css" />
    <link rel="stylesheet" href="/wayverb/assets/css/font-awesome.min.css" />
	<!--[if lte IE 9]><link rel="stylesheet" href="/wayverb/assets/css/ie9.css" /><![endif]-->
	<!--[if lte IE 8]><link rel="stylesheet" href="/wayverb/assets/css/ie8.css" /><![endif]-->

<!-- Scripts -->
<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
</head>

<body>
<nav id="sidebar_nav">
    <a href="/wayverb/" class="title">Wayverb</a>
    <ul>
        
        
            <li>
                <a href="/wayverb/introduction.html" >
                    Introduction
                </a>
            </li>
        
            <li>
                <a href="/wayverb/context.html" >
                    Context
                </a>
            </li>
        
            <li>
                <a href="/wayverb/image_source.html" >
                    Image-source
                </a>
            </li>
        
            <li>
                <a href="/wayverb/ray_tracer.html" >
                    Ray tracer
                </a>
            </li>
        
            <li>
                <a href="/wayverb/waveguide.html" >
                    Waveguide
                </a>
            </li>
        
            <li>
                <a href="/wayverb/hybrid.html" class="active">
                    Hybrid
                </a>
            </li>
        
            <li>
                <a href="/wayverb/microphone.html" >
                    Microphone modelling
                </a>
            </li>
        
            <li>
                <a href="/wayverb/boundary.html" >
                    Boundary modelling
                </a>
            </li>
        
            <li>
                <a href="/wayverb/evaluation.html" >
                    Evaluation and Future
                </a>
            </li>
        
            <li>
                <a href="/wayverb/demos.html" >
                    Demos
                </a>
            </li>
        
            <li>
                <a href="/wayverb/bibliography.html" >
                    References
                </a>
            </li>
        
    </ul>
</nav>

<div id="page_main">
    <header>
        <ul>
            <li class="nav_menu open" >
                <a href="#sidebar_nav">
                    &#9776;
                </a>
            </li>
            <li class="nav_menu close" >
                <a href="#">
                    &#9776;
                </a>
            </li>
            <li>
                <a href="/wayverb/" >
                    Wayverb
                </a>
            </li>
        </ul>
    </header>
    <div class="inner">
        <nav id="prev_next_nav">
    
    
        
    
        
    
        
    
        
    
        
    
        
            
            
            
                <a href="/wayverb/waveguide.html" class="prev_page">Waveguide</a>
            

            
            
            
                <a href="/wayverb/microphone.html" class="next_page">Microphone modelling</a>
            
        
    
        
    
        
    
        
    
        
    
        
    
</nav>

        <div id="TOC">
<ul>
<li><a href="#hybrid">Hybrid</a><ul>
<li><a href="#background">Background</a></li>
<li><a href="#transitions">Transitions</a><ul>
<li><a href="#early-and-late-reflections">Early and Late Reflections</a></li>
<li><a href="#crossover-position">Crossover Position</a></li>
</ul></li>
<li><a href="#level-matching">Level Matching</a><ul>
<li><a href="#image-source-and-ray-tracer">Image-Source and Ray Tracer</a></li>
<li><a href="#geometric-and-waveguide">Geometric and Waveguide</a></li>
</ul></li>
</ul></li>
<li><a href="#bibliography">References</a></li>
</ul>
</div>
<h1 id="hybrid" class="major">Hybrid</h1>
<h2 id="background">Background</h2>
<p>The previous sections have looked at the theory and implementation of three different acoustic simulation techniques. The image-source method is accurate for early reflections, but slow for longer responses. The ray tracing method is inaccurate, but produces acceptable responses for “diffuse” reverb tails. The waveguide method models physical phenomena better than the geometric methods, but is expensive at high frequencies. By combining all three models together, accurate broadband impulse responses can be created, without requiring exceptional computing power.</p>
<p>This section will focus on the two most important factors governing the combination of modelling techniques. The first is positioning transitions: in the time domain, from early to late reflections; and in the frequency domain, between geometric and waveguide modelling. The second is matching the output levels of the different methods, so that there are no sudden discontinuities in level, and the transitions are seamless.</p>
<h2 id="transitions">Transitions</h2>
<h3 id="early-and-late-reflections">Early and Late Reflections</h3>
<p>The beginning of the image-source process relies on randomly ray tracing a certain number of reflections. This ray tracing process is similar to that used for estimating late, diffuse reflections. When the simulation is run in Wayverb, rays are actually traced to a depth of maybe 100 reflections or more. The first few reflections are routed to image-source processing, while the entire set of reflections is used for finding the reverb tail.</p>
<p>It is important to note that the stochastic ray tracing process will record both specular and diffuse reflections. At the beginning of the impulse response, this will lead to a duplication of energy, as the energy from specular reflections will be recorded by both the image-source and ray-tracing processes. To solve this problem, the stochastic ray tracer records specular and diffuse contributions separately. Specular contributions from the ray tracer are only added to the output for reflections of higher order than the highest image-source order.</p>
<p>Surface scattering also poses a problem. When simulating scenes with high surface scattering coefficients, specular reflections should be quiet, with a greater degree of scattered energy. Unfortunately, the image-source process cannot account for scattered sound energy by design. The solution is to use diffuse contributions from the stochastic ray tracer, so that the image-source and ray-traced outputs “overlap”. To ensure that the amount of energy in the simulation remains constant, the image-source finder must account for energy lost to scattering during reflections. Therefore, after finding the reflectance of each surface using the method outlined above, the reflectance is further multiplied by <span class="math inline">\((1 - s)\)</span> where s is the frequency-dependent scattering coefficient of the surface. This causes the image-source contributions to die away faster, and the “missing” energy will be made up by the diffuse output of the ray tracer.</p>
<p>The transition between the image-source and ray tracing models will generally overlap. The image-source response will fade away as the ray-traced diffuse reflections become louder. The exact number of early reflections to be found with the image-source method is largely a subjective decision. For diffuse rooms, the early specular reflections will be very quiet, regardless of which method is used, so it is appropriate to set the number of specular reflections very low, or even to disable image-source contributions altogether. For rooms with surfaces which are large, smooth, and flat, specular reflections will form a more significant part of the room response, and so it is reasonable to use deeper image-source reflections in this case. Even under these conditions, an image-source depth of more than 5 or 6 is unnecessary: in virtually all scenes, some incident sound energy will be scattered diffusely, and the conversion of “specular energy” into “scattered energy” is unidirectional, meaning that late reflections in all scenes will be diffuse, and therefore suitable for simulation with stochastic ray-tracing methods <span class="citation" data-cites="kuttruff_room_2009">[<a href="#ref-kuttruff_room_2009">1</a>, p. 126]</span>.</p>
<h3 id="crossover-position">Crossover Position</h3>
<p>In the interests of efficiency, the most accurate waveguide method is only used at low frequencies, where it is relatively cheap. The rest of the audible spectrum is modelled with geometric methods, which are most accurate at higher frequencies. However, there is no concrete rule to place the crossover between “low” and “high” frequencies in this context. It should be clear that, when the time and computing power is available, the cutoff should be placed as high as possible, so as to use accurate wave-based modelling for the majority of the output. However, in practice, it might be useful to have an estimate for the frequencies where wave-modelling is strictly required, to guide the placement of the cutoff frequency. The <em>Schroeder frequency</em> is such an estimate, and is based on the density of room resonances or “modes”. Below the Schroeder frequency, room modes are well separated and can be individually excited. Above, the room modes overlap much more, resulting in a more “even” and less distinctly resonant sound. The Schroeder frequency is defined as follows (see <span class="citation" data-cites="kuttruff_room_2009">[<a href="#ref-kuttruff_room_2009">1</a>, p. 84]</span> for a detailed derivation):</p>
<ol class="example" type="1">
<li><span class="math display">\[2000\sqrt{\frac{RT60}{V}}\]</span></li>
</ol>
<p>Here, <span class="math inline">\(RT60\)</span> is the time taken for the reverb tail to decay by 60dB, and <span class="math inline">\(V\)</span> is the room volume in cubic metres. Note that the Schroeder frequency is inversely proportional to the square root of the room volume. This implies that in larger rooms, the shift from modal to non-modal behaviour is lower, and therefore wave-based methods will be required to compute a smaller portion of the spectrum. In turn, this helps to keep the computational cost of the waveguide simulations within reasonable bounds. Although the cost of wave-based methods increases with output frequency and simulation size, larger simulations require a lower maximum output frequency. As a result, a hybrid acoustic simulator should be able to simulate even very large enclosures with reasonable perceived accuracy, without incurring excessive costs.</p>
<h2 id="level-matching">Level Matching</h2>
<h3 id="image-source-and-ray-tracer">Image-Source and Ray Tracer</h3>
<p>The <a href="/wayverb/image_source.html">Image Source</a> model operates in terms of pressure. This means that the pressure contribution of each individual image is inversely proportional to the distance between that image source and the receiver. In contrast, the <a href="/wayverb/ray_tracer.html">Ray Tracing</a> method operates in terms of acoustic intensity, and the total intensity measured at the receiver depends only on the number of rays which intersect with it. The distance travelled by each ray is not taken into account.</p>
<p>A method for equalising the output of the two models is given in <span class="citation" data-cites="schroder_physically_2011">[<a href="#ref-schroder_physically_2011">2</a>, p. 75]</span>. The goal of the method is to ensure that the energy of the direct contribution (the wave-front travelling directly from source to receiver, with no intermediate reflections) is equal between the two models.</p>
<p>First, equations for the intensity at the receiver must be created. Given a source and receiver separated by distance <span class="math inline">\(r\)</span>, the intensity of the direct image-source contribution is given by:</p>
<ol start="2" class="example" type="1">
<li><span class="math display">\[E_{\text{image source}}=\frac{E_{\text{source}}}{4\pi r^2}\]</span></li>
</ol>
<p>For the ray tracing method, the intensity of the direct contribution is a function of the number of rays <span class="math inline">\(N\)</span>, and the intensity of each ray <span class="math inline">\(E_r\)</span>. Only rays intersecting the receiver will be registered, so ray intensity must be normalised taking into account the proportion of rays which will intersect the receiver. For a spherical receiver, and uniformly distributed rays, the proportion of rays which intersect the receiver is the ratio between the area covered by the receiver, and the total area over which the rays are distributed. If the receiver is at a distance <span class="math inline">\(r\)</span> from the source, with an opening angle <span class="math inline">\(\gamma\)</span>, then its area is that of a spherical cap (see the following figure):</p>
<ol start="3" class="example" type="1">
<li><span class="math display">\[ A_{\text{intersection}} = 2\pi r^2(1-\cos\gamma) \]</span></li>
</ol>
<p>Then, the total direct energy registered by the ray tracer can be expressed:</p>
<ol start="4" class="example" type="1">
<li><span class="math display">\[
\begin{aligned}
E_{\text{ray tracer}} &amp; = NE_r \left( \frac{A_{\text{intersection}}}{4\pi r^2} \right) \\
                  &amp; = NE_r \left( \frac{2\pi r^2(1-\cos\gamma)}{4\pi r^2} \right) \\
                  &amp; = NE_r \left( \frac{1-\cos\gamma}{2} \right)
\end{aligned}
\]</span></li>
</ol>
<figure>
<img src="images/detected_energy.svg" alt="The proportion of uniformly-distributed rays intersecting the receiver depends on the distance to the source, and opening angle formed by the receiver. The acoustic intensity registered by the ray tracer is given by the number of rays which intersect the receiver, and the energy carried by each ray." /><figcaption>The proportion of uniformly-distributed rays intersecting the receiver depends on the distance to the source, and opening angle formed by the receiver. The acoustic intensity registered by the ray tracer is given by the number of rays which intersect the receiver, and the energy carried by each ray.</figcaption>
</figure>
<p>The direct energy in both models should be equal, so the two equations can be set equal to one another, giving an equation for the initial intensity of each ray, in terms of the source intensity <span class="math inline">\(E_{\text{source}}\)</span>, the opening angle of the receiver <span class="math inline">\(\gamma\)</span>, and the number of rays <span class="math inline">\(N\)</span>.</p>
<ol start="5" class="example" type="1">
<li><span class="math display">\[
\begin{aligned}
E_{\text{ray tracer}} &amp;= E_{\text{image source}} \\
NE_r \left( \frac{1-\cos\gamma}{2} \right) &amp;= \frac{E_{\text{source}}}{4\pi r^2} \\
E_r &amp;= \frac{E_{\text{source}}}{2 \pi r^2 N (1 - \cos\gamma)}
\end{aligned}
\]</span></li>
</ol>
<p>As long as the initial ray intensities are set according to this equation, both methods will produce outputs with the correct relative levels. The outputs from the two methods are combined by simple signal addition, with no need for additional level adjustment.</p>
<h3 id="geometric-and-waveguide">Geometric and Waveguide</h3>
<p>Setting the waveguide mesh level should follow a similar procedure. The waveguide output level should be normalised so that the direct intensity observed at the receiver is equal to that observed in the image-source model. The normalisation is achieved through the use of a <em>calibration coefficient</em> which can be used to scale the waveguide output, or alternatively to adjust the magnitude of the input signal.</p>
<p>Several suggestions for finding the calibration coefficient are suggested in the literature. One option, which is perhaps the simplest (short of manual calibration), is found in <span class="citation" data-cites="southern_spatial_2011">[<a href="#ref-southern_spatial_2011">3</a>]</span>. The average magnitude of a certain frequency band is calculated for both the waveguide and geometric output. The calibration coefficient is then equal to the ratio of these two magnitudes. This approach is flawed, in that the frequency band used must have the same bounds, or at least close, for both signals. The frequency band will therefore be towards the lower end of the geometric output, which is known to be inaccurate (this is the entire reason for hybrid modelling). It is impossible to compute an accurate calibration coefficient from inaccurate data.</p>
<p>Another method, suggested in the same paper <span class="citation" data-cites="southern_spatial_2011">[<a href="#ref-southern_spatial_2011">3</a>]</span>, is to find the intensity produced by the waveguide at a distance of 1m, and then to normalise both models so that they produce the same intensity at this distance. The image-source direct response is low-pass filtered, so that it only contains energy in the same frequency band as the waveguide output. Then, the maximum magnitude in the initial portion (up to the first reflection) of the output signal is found, for the image-source and waveguide output. The calibration parameter is found by taking the ratio of these maximum magnitudes. This differs from the first technique, in that the calibration coefficient is derived from a single contribution in the time-domain, instead of from frequency-domain magnitudes accumulated over the entire duration of the signal.</p>
<p>The second method is superior, in that it will produce an accurate calibration coefficient. Unfortunately, it requires analysis of the waveguide output signal which, while not time-consuming, seems unnecessary. A given mesh topology and excitation signal should always require the same calibration coefficient, assuming that the geometric source level remains constant. It should be possible to calculate the calibration coefficient for a certain mesh topology, and then to re-use this coefficient across simulations. This is the approach taken in <span class="citation" data-cites="siltanen_finite-difference_2013">[<a href="#ref-siltanen_finite-difference_2013">4</a>]</span>.</p>
<p>This general calibration coefficient is found by exciting a waveguide mesh with an impulsive signal, and recording the pressure at a receiver node immediately adjacent to the source node. The simulation continues until the magnitude of vibrations at the receiver have reduced below some threshold (perhaps falling below the noise floor). Now, the change in pressure at a distance <span class="math inline">\(X\)</span> is known, where <span class="math inline">\(X\)</span> is the inter-nodal spacing of the waveguide mesh. The geometric pressure level at the same distance is given by</p>
<ol start="6" class="example" type="1">
<li><span class="math display">\[ p_g=\sqrt{\frac{PZ_0}{4\pi}} / X \]</span></li>
</ol>
<p>where <span class="math inline">\(P\)</span> is the source strength and <span class="math inline">\(Z_0\)</span> is the acoustic impedance of air. The waveguide pressure level cannot be directly compared to the geometric pressure level, because the upper portion of the waveguide output frequency range is invalid. The waveguide output must, therefore, be low-pass filtered to extract the valid portion of the spectrum. If the low-pass cutoff is set low enough, then only the DC component of the waveguide output will remain. This DC component can more simply be found simply by accumulating the signal at the receiver. Now, the calibration coefficient <span class="math inline">\(\eta\)</span> can be expressed like so:</p>
<ol start="7" class="example" type="1">
<li><span class="math display">\[\eta = \frac{p_\text{init}R}{p_\text{DC}X}\]</span></li>
</ol>
<p>where <span class="math inline">\(p_\text{init}\)</span> and <span class="math inline">\(p_\text{DC}\)</span> are the initial and DC pressure levels respectively, <span class="math inline">\(X\)</span> is the inter-nodal spacing, and <span class="math inline">\(R\)</span> is the distance at which the <em>geometric</em> source has intensity 1W/m².</p>
<p>Experimentally-obtained values of <span class="math inline">\(\frac{p_\text{DC}}{p_\text{init}}\)</span> are given in <span class="citation" data-cites="siltanen_finite-difference_2013">[<a href="#ref-siltanen_finite-difference_2013">4</a>]</span> for several different mesh topologies. To produce normalised waveguide outputs, a calibration coefficient is calculated, using the experimental result corresponding to a rectilinear mesh. The waveguide excitation is then scaled by this calibration coefficient.</p>
<h4 id="testing">Testing</h4>
<p>To validate the waveguide calibration procedure, a simple cuboid-shaped room is simulated using the image-source and waveguide methods. The outputs are compared in the frequency-domain, to ensure that the modal responses of the two models match, in shape and in magnitude.</p>
<p>For cuboid rooms with perfectly reflective surfaces, the image-source method is exact <span class="citation" data-cites="kuttruff_room_2009">[<a href="#ref-kuttruff_room_2009">1</a>]</span>, and it remains reasonably accurate for slightly-absorbing surfaces. Additionally, for this room shape, the image source method can be dramatically accelerated, making it possible to calculate extended impulse responses <span class="citation" data-cites="allen_image_1979">[<a href="#ref-allen_image_1979">5</a>]</span>. This accelerated method differs from Wayverb’s image-source finder, in that it can calculate long impulse responses for one specific room shape, whereas Wayverb’s can calculate short responses for arbitrary geometry.</p>
<p>If the accelerated method is implemented, it can be used to generate impulse responses which are close to ideal (depending on the surface absorptions used). These impulse responses can be compared to those produced by the waveguide, and if the calibration coefficient has been chosen correctly, then their frequency responses should match.</p>
<!-- TODO is it worth talking about implementation issues for the accelerated image-source? -->
<p>A room, measuring <span class="math inline">\(5.56 \times 3.97 \times 2.81\)</span> metres is simulated, using the accelerated image-source and waveguide methods. The source is placed at (1, 1, 1), with a receiver at (2, 3, 1.5). Both methods are run at a sampling rate of 16KHz. The simulation is carried out three times, with surface absorptions of 0.2, 0.1, and 0.05, and in all cases the simulation is run up until the Sabine-estimated RT60, which is 0.52, 1.03 and 2.06 seconds respectively. The resulting frequency responses are shown below.</p>
<figure>
<img src="images/calibration.svg" alt="Frequency responses analysis of image-source and waveguide outputs. The initial waveguide level has been calibrated using the technique described above.Room mode frequencies are shown in grey." /><figcaption>Frequency responses analysis of image-source and waveguide outputs. The initial waveguide level has been calibrated using the technique described above.Room mode frequencies are shown in grey.</figcaption>
</figure>
<p>The frequency responses match closely, to with a decibel between 30 and 70Hz. There is some divergence at 80Hz, after which the results match closely again until the upper limit of 200Hz. At the upper end of the spectrum, the levels match closely between outputs, but the peaks and troughs are slightly “shifted”.</p>
<p>There are several possible causes for the differences seen between the outputs of the different models. Firstly, the image-source technique is only exact for perfectly reflecting boundaries. The boundary model used in this image-source implementation is the same locally-reacting surface model that Wayverb uses: the reflection factor is real-valued and angle-dependent. A more physically correct method would be to use complex reflection factors, which would allow phase changes at boundaries to be represented. The boundary model is almost certainly the cause of the largest discrepancy, at around 80Hz: results given in <span class="citation" data-cites="aretz_combined_2009">[<a href="#ref-aretz_combined_2009">6</a>, p. 78]</span> show similar artefacts of the real-value angle-dependent reflection factor, compared against other more accurate image-source boundary types. Due to time constraints, these more complicated boundary models could not be tested here.</p>
<p>The small frequency shift at the top of the spectrum is most likely to be caused by numerical dispersion in the waveguide mesh. Numerical dispersion becomes more pronounced as frequency increases, which is consistent with the shift seen in the results, which is greater at higher frequencies. The shift may also be caused by slight differences in the dimensions of the modelled room, or the source and receiver positions. In the image-source model, all measurements and positions are exact, but the waveguide must “quantise” the boundary, source, and receiver positions so that they coincide with mesh nodes. If the dimensions of the room were adjusted slightly, this would also cause the room modes to change (which again would be more pronounced at higher frequencies), which might lead to a perceived spectral shift relative to a room with exact dimensions.</p>
<p>Despite the small differences, between the frequency responses, the close level match between models suggests that the calibration coefficient is correct.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-kuttruff_room_2009">
<p>[1] H. Kuttruff, <em>Room Acoustics, Fifth Edition</em>. CRC Press, 2009. </p>
</div>
<div id="ref-schroder_physically_2011">
<p>[2] D. Schröder, <em>Physically based real-time auralization of interactive virtual environments</em>, vol. 11. Logos Verlag Berlin GmbH, 2011 [Online]. Available: <a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=HtDxSt0jcRkC&amp;oi=fnd&amp;pg=PR17&amp;dq=+Dirk+Schro+%CC%88der+Physically+Based+Real-Time+Auralization+of+Interactive+Virtual+Environments&amp;ots=CCbCVBNlmn&amp;sig=CAlxZysU-fxjnSkG_X1_dffQ72o">https://books.google.com/books?hl=en&amp;lr=&amp;id=HtDxSt0jcRkC&amp;oi=fnd&amp;pg=PR17&amp;dq=+Dirk+Schro+%CC%88der+Physically+Based+Real-Time+Auralization+of+Interactive+Virtual+Environments&amp;ots=CCbCVBNlmn&amp;sig=CAlxZysU-fxjnSkG_X1_dffQ72o</a>. [Accessed: 05-Dec-2016]</p>
</div>
<div id="ref-southern_spatial_2011">
<p>[3] A. Southern, S. Siltanen, and L. Savioja, “Spatial room impulse responses with a hybrid modeling method,” in <em>Audio Engineering Society Convention 130</em>, 2011 [Online]. Available: <a href="http://www.aes.org/e-lib/browse.cfm?elib=15852" class="uri">http://www.aes.org/e-lib/browse.cfm?elib=15852</a>. [Accessed: 05-Dec-2016]</p>
</div>
<div id="ref-siltanen_finite-difference_2013">
<p>[4] S. Siltanen, A. Southern, and L. Savioja, “Finite-difference time domain method source calibration for hybrid acoustics modeling,” in <em>2013 IEEE International Conference on Acoustics, Speech and Signal Processing</em>, 2013, pp. 166–170 [Online]. Available: <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6637630" class="uri">http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6637630</a>. [Accessed: 05-Dec-2016]</p>
</div>
<div id="ref-allen_image_1979">
<p>[5] J. B. Allen and D. A. Berkley, “Image method for efficiently simulating small-room acoustics,” <em>The Journal of the Acoustical Society of America</em>, vol. 65, no. 4, pp. 943–950, 1979 [Online]. Available: <a href="http://scitation.aip.org/content/asa/journal/jasa/65/4/10.1121/1.382599" class="uri">http://scitation.aip.org/content/asa/journal/jasa/65/4/10.1121/1.382599</a>. [Accessed: 05-Dec-2016]</p>
</div>
<div id="ref-aretz_combined_2009">
<p>[6] M. Aretz, R. Nöthen, M. Vorländer, and D. Schröder, “Combined broadband impulse responses using FEM and hybrid ray-based methods,” in <em>EAA Symposium on Auralization</em>, 2009 [Online]. Available: <a href="https://www.researchgate.net/profile/Dirk_Schroeder/publication/258098666_Combined_Broadband_Impulse_Responses_Using_FEM_and_Hybrid_Ray-Based_Methods/links/54fd4d800cf2c3f52424436f.pdf" class="uri">https://www.researchgate.net/profile/Dirk_Schroeder/publication/258098666_Combined_Broadband_Impulse_Responses_Using_FEM_and_Hybrid_Ray-Based_Methods/links/54fd4d800cf2c3f52424436f.pdf</a>. [Accessed: 05-Dec-2016]</p>
</div>
</div>

        <nav id="prev_next_nav">
    
    
        
    
        
    
        
    
        
    
        
    
        
            
            
            
                <a href="/wayverb/waveguide.html" class="prev_page">Waveguide</a>
            

            
            
            
                <a href="/wayverb/microphone.html" class="next_page">Microphone modelling</a>
            
        
    
        
    
        
    
        
    
        
    
        
    
</nav>

    </div>
    <footer id="footer" class="wrapper alt">
    <div class="inner">
        <ul class="menu">
			<li>
                &copy; Reuben Thomas 2016. All rights reserved.
            </li>
            <li>
                Design: <a href="http://html5up.net">HTML5 UP</a>, modified by Reuben Thomas.
            </li>
		</ul>
	</div>
</footer>

<!-- Scripts -->
<script src="/wayverb/assets/js/jquery.min.js"></script>
<script src="/wayverb/assets/js/jquery.scrollex.min.js"></script>
<script src="/wayverb/assets/js/jquery.scrolly.min.js"></script>
<script src="/wayverb/assets/js/skel.min.js"></script>
<script src="/wayverb/assets/js/util.js"></script>
<!--[if lte IE 8]><script src="/wayverb/assets/js/ie/respond.min.js"></script><![endif]-->
<script src="/wayverb/assets/js/main.js"></script>

</div>
</body>
</html>
