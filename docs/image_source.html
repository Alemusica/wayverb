<!DOCTYPE HTML>
<html>
<head>
    <title>Wayverb - Image-source</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="/wayverb/assets/favicon.ico" />
	<!--[if lte IE 8]><script src="/wayverb/assets/js/ie/html5shiv.js"></script><![endif]-->
	<link rel="stylesheet" href="/wayverb/assets/css/main.css" />
    <link rel="stylesheet" href="/wayverb/assets/css/font-awesome.min.css" />
	<!--[if lte IE 9]><link rel="stylesheet" href="/wayverb/assets/css/ie9.css" /><![endif]-->
	<!--[if lte IE 8]><link rel="stylesheet" href="/wayverb/assets/css/ie8.css" /><![endif]-->

<!-- Scripts -->
<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
</head>

<body>
<nav id="sidebar_nav">
    <a href="/wayverb/" class="title">Wayverb</a>
    <ul>
        
        
            <li>
                <a href="/wayverb/introduction.html" >
                    Introduction
                </a>
            </li>
        
            <li>
                <a href="/wayverb/context.html" >
                    Context
                </a>
            </li>
        
            <li>
                <a href="/wayverb/image_source.html" class="active">
                    Image-source
                </a>
            </li>
        
            <li>
                <a href="/wayverb/ray_tracer.html" >
                    Ray tracer
                </a>
            </li>
        
            <li>
                <a href="/wayverb/waveguide.html" >
                    Waveguide
                </a>
            </li>
        
            <li>
                <a href="/wayverb/hybrid.html" >
                    Hybrid
                </a>
            </li>
        
            <li>
                <a href="/wayverb/microphone.html" >
                    Microphone modelling
                </a>
            </li>
        
            <li>
                <a href="/wayverb/boundary.html" >
                    Boundary modelling
                </a>
            </li>
        
            <li>
                <a href="/wayverb/evaluation.html" >
                    Evaluation and Future
                </a>
            </li>
        
            <li>
                <a href="/wayverb/demos.html" >
                    Demos
                </a>
            </li>
        
            <li>
                <a href="/wayverb/bibliography.html" >
                    References
                </a>
            </li>
        
    </ul>
</nav>

<div id="page_main">
    <header>
        <ul>
            <li class="nav_menu open" >
                <a href="#sidebar_nav">
                    &#9776;
                </a>
            </li>
            <li class="nav_menu close" >
                <a href="#">
                    &#9776;
                </a>
            </li>
            <li>
                <a href="/wayverb/" >
                    Wayverb
                </a>
            </li>
        </ul>
    </header>
    <div class="inner">
        <nav id="prev_next_nav">
    
    
        
    
        
    
        
            
            
            
                <a href="/wayverb/context.html" class="prev_page">Context</a>
            

            
            
            
                <a href="/wayverb/ray_tracer.html" class="next_page">Ray tracer</a>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
</nav>

        <div id="TOC">
<ul>
<li><a href="#image-source">Image-source</a><ul>
<li><a href="#background">Background</a><ul>
<li><a href="#basic-method">Basic Method</a></li>
<li><a href="#validity-checks">Validity Checks</a></li>
<li><a href="#acceleration">Acceleration</a></li>
</ul></li>
<li><a href="#implementation">Implementation</a></li>
</ul></li>
<li><a href="#bibliography">References</a></li>
</ul>
</div>
<h1 id="image-source" class="major">Image-source</h1>
<h2 id="background">Background</h2>
<h3 id="basic-method">Basic Method</h3>
<p>The image-source method aims to find the purely specular reflection paths between a source and a receiver. This relies on the simplifying assumption that sound propagates only along straight lines or “rays”. Sound energy travels at a fixed speed, corresponding to the speed of sound, along these rays. The intensity of each “packet” of sound energy decreases with <span class="math inline">\(1/r^2\)</span>, where <span class="math inline">\(r\)</span> is the distance along the ray that the packet has travelled <span class="citation" data-cites="vorlander_auralization:_2007">[<a href="#ref-vorlander_auralization:_2007">1</a>, p. 58]</span>.</p>
<p>Rays are perfectly reflected at boundaries. When a ray is reflected, it spawns a secondary source “behind” the boundary surface. This source is located on a line perpendicular to the wall, at the same distance from it as the original source, as if the original source has been “mirrored” in the surface. This is a first-order reflection. A ray which is reflected from several boundaries is represented by a “higher-order” image-source, which has been mirrored in each of those boundaries in turn <span class="citation" data-cites="kuttruff_room_2009">[<a href="#ref-kuttruff_room_2009">2</a>, p. 104]</span>.</p>
<figure>
<img src="images/image_source_construction.svg" alt="Image sources are found by reflecting the source position in a boundary." /><figcaption>Image sources are found by reflecting the source position in a boundary.</figcaption>
</figure>
<p>All sources, original and image, emit the same impulsive source signal at the same time. The total impulse response (i.e. sound pressure against time) is found by summing the signals from each source, delayed and attenuated appropriately depending on the distance between that source and the receiver. The frequency response of the signal from each image source will additionally be modified depending on the characteristics of the boundaries in which that source was reflected.</p>
<p>Each image source represents a perfect specular reflection, so there is no way for the image model to calculate scattered or diffuse responses. Though this may sound troubling, it is not very problematic. The conversion of specular into diffuse sound energy is unidirectional, so repeated reflections cause the ratio of scattered to specular energy to increase monotonically. It is shown in <span class="citation" data-cites="kuttruff_room_2009">[<a href="#ref-kuttruff_room_2009">2</a>, p. 126]</span> that though the earliest reflections may be largely specular, after a few reflections the large majority of sound energy becomes diffuse. This suggests that the image model should be used only for very early reflections, and a secondary model used to compute late, diffuse reflections.</p>
<h3 id="validity-checks">Validity Checks</h3>
<p>Having found the position of an image-source, by reflecting it in one or more surfaces, it must be checked to ensure it represents a specular path to the receiver. This is known as an <em>audibility test</em> <span class="citation" data-cites="vorlander_auralization:_2007">[<a href="#ref-vorlander_auralization:_2007">1</a>, p. 202]</span>.</p>
<p>Consider first a source <span class="math inline">\(S\)</span>, a receiver <span class="math inline">\(R\)</span>, and a single wall <span class="math inline">\(A\)</span>. The source is reflected in <span class="math inline">\(A\)</span>, creating an image-source <span class="math inline">\(S_A\)</span>. A line is constructed from <span class="math inline">\(R\)</span> to <span class="math inline">\(S_A\)</span>. If this line intersects <span class="math inline">\(A\)</span>, then <span class="math inline">\(S_A\)</span> represents a valid image source. Otherwise, there is no possible specular reflection involving <span class="math inline">\(S\)</span>, <span class="math inline">\(R\)</span> and <span class="math inline">\(A\)</span>.</p>
<p>Now consider two walls, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. The image source <span class="math inline">\(S_{AB}\)</span> has been reflected in <span class="math inline">\(A\)</span> then <span class="math inline">\(B\)</span>. For the image-source to be valid:</p>
<ul>
<li><span class="math inline">\(R \rightarrow S_{AB}\)</span> must intersect <span class="math inline">\(B\)</span> at some point <span class="math inline">\(B_\text{intersection}\)</span>,</li>
<li><span class="math inline">\(B_\text{intersection} \rightarrow S_A\)</span> must intersect <span class="math inline">\(A\)</span> at <span class="math inline">\(A_\text{intersection}\)</span>, <em>and</em></li>
<li><span class="math inline">\(A_\text{intersection} \rightarrow S\)</span> must not intersect with any scene geometry.</li>
</ul>
<p>The validation of a third-order image-source will require three intersection checks, a fourth-order image will require four checks, and so on. This method of tracing backwards from the receiver to each of the image sources is known as <em>backtracking</em>.</p>
<figure>
<img src="images/backtracking.svg" alt="Left: The paths S \rightarrow A \rightarrow R and S \rightarrow A \rightarrow B \rightarrow R are both valid. Right: S \rightarrow B \rightarrow A \rightarrow R is an invalid path because R \rightarrow S_{BA} does not intersect A." /><figcaption><strong>Left:</strong> The paths <span class="math inline">\(S \rightarrow A \rightarrow R\)</span> and <span class="math inline">\(S \rightarrow A \rightarrow B \rightarrow R\)</span> are both valid. <strong>Right:</strong> <span class="math inline">\(S \rightarrow B \rightarrow A \rightarrow R\)</span> is an invalid path because <span class="math inline">\(R \rightarrow S_{BA}\)</span> does not intersect <span class="math inline">\(A\)</span>.</figcaption>
</figure>
<h3 id="acceleration">Acceleration</h3>
<p>The naive method to find all the image sources for a scene is very expensive. Consider that to find a single first-order image source, the original source must be mirrored in a surface, and then an intersection test must be conducted between that surface and the image-source-to-receiver ray. To find all first-order image sources, this process must be carried out for all surfaces in the scene. To find all second-order image sources, each of those first-order images must be tested against every surface. This continues for higher-order images, so that the number of checks for image sources of a given order is equal to the number of surfaces raised to the power of that order. The relationship between the image-source order and the computation time is therefore exponential, meaning that high orders are impossible to compute in a reasonable time.</p>
<p>The majority of higher-order image sources found with the naive algorithm will be invalid. That is, they will fail the visibility/intersection test. For example, <span class="citation" data-cites="kuttruff_room_2009">[<a href="#ref-kuttruff_room_2009">2</a>, p. 323]</span> shows that, for tenth-order image-sources in a shoebox-shaped room, there are around 1.46e7 different image sources, only 1560 of which are valid. If the invalid image-sources can be discarded early, without requiring individual checking, then the amount of computation can be greatly reduced to a viable level. As explained above, image sources above order four or five are rarely required, but even these can be very time-consuming to find with the naive method. Optimisations are, therefore, a necessity for any but the simplest simulations.</p>
<p>To accelerate the image-source process, <span class="citation" data-cites="vorlander_auralization:_2007">[<a href="#ref-vorlander_auralization:_2007">1</a>]</span> suggests tracing a large number of rays in random directions from the source, and logging the unique paths of rays which eventually intersect with the receiver. Each unique path found in this way is used to generate an image source sequence, which is then checked as normal. This technique has the advantage that the majority of surface sequences are <em>not</em> checked, so the image-source process is fast. However, if the preliminary ray-tracer is not run with enough rays, it is likely to miss some valid paths, especially in complex scenes. Additionally, if the receiver volume is too great, then some invalid paths may still be detected.</p>
<p>The technique used by Wayverb is similar to that presented in <span class="citation" data-cites="vorlander_auralization:_2007">[<a href="#ref-vorlander_auralization:_2007">1</a>]</span>, but makes a small change. A large number of random rays are traced, as before, but at each reflection point, the receiver is checked to see whether it is visible. If it is, then the surface sequence is checked for a valid image-source. This technique has two main advantages: more paths are checked, so it is more likely to find all the valid image-sources; and ray paths don’t have to be specular, so ray-tracing can use techniques like <em>vector-based scattering</em>. The disadvantage is that a greater number of validity checks are required, though this number is still many times smaller than would be required by a naive implementation.</p>
<h2 id="implementation">Implementation</h2>
<p>Here the concrete implementation of the image-source method is presented, as it is used in Wayverb. Details of the microphone-modelling process are discussed separately, in the <a href="/wayverb/microphone.html">Microphone Modelling</a> section. The following image  gives an overview of the entire process.</p>
<figure>
<img src="images/image_source_process.svg" alt="Creation of an impulse response using image sources." /><figcaption>Creation of an impulse response using image sources.</figcaption>
</figure>
<!--
The simulation prerequisites are:

* source position 
* receiver position 
* speed of sound in air 
* acoustic impedance of air 
* a scene, made up of triangles, where each triangle has an associated material
  comprised of multiband absorption and scattering coefficients (note that 
  curved surfaces are not supported, and must be approximated by small 
  triangles)
-->
<p>First, an axis-aligned bounding box is computed for the scene, and split into uniformly sized cuboid <em>voxels</em>. Each voxel holds a reference to any triangles in the scene which happen to intersect with that voxel. The voxel mesh acts as an “acceleration structure”, speeding up intersection tests between rays and triangles. To check for an intersection between a ray and a number of triangles, the simplest method is to check the ray against each triangle individually, which is very time consuming. The voxel mesh allows the number to checks to be greatly reduced, by checking only triangles that are within voxels that the ray intersects. These voxels can be found very quickly, by “walking” the voxels along the ray, using an algorithm presented in <span class="citation" data-cites="amanatides_fast_1987">[<a href="#ref-amanatides_fast_1987">3</a>]</span>. For large scenes with many triangles, this method can lead to speed-ups of an order of magnitude or more. Assume all ray-intersection tests mentioned throughout this thesis use the voxel-acceleration method, unless explicitly noted.</p>
<p>Rays are fired in uniform random directions from the source. Each ray is checked for an intersection with the scene, and if an intersection is found, some data about the intersection is recorded. Specifically, the record includes the triangle which was intersected, and whether or not the receiver is visible from the intersection point. Then, the vector-based scattering method <span class="citation" data-cites="christensen_new_2005">[<a href="#ref-christensen_new_2005">4</a>]</span> is used to find the directions of new rays, which are fired from the intersection points. The ray-tracing process continues up to a certain depth, which is artificially limited to ten reflections in Wayverb. For most simulations, three or four reflections should be adequate, though this depends somewhat on the scattering coefficients of the surfaces, as explained in the <a href="#basic-method">Basic Method</a> subsection.</p>
<p>The ray tracer produces a list of reflection paths for each ray. Some rays may follow the same paths, and so duplicates must be removed. This is achieved by condensing per-ray information into a tree of valid paths. Each node in the tree stores a reference to a triangle in the scene, and whether or not the receiver is visible from this triangle. Each unique path starting from a root node in the tree represents a possible image source contribution, which must be checked. This checking is carried out using the backtracking method explained above. A nice property of the tree structure is that it can be traversed using depth-first recursion, allowing the results of some intermediate calculations to be cached between ray paths, speeding up the calculation with only minimal memory overhead. This is similar to the approach mentioned in <span class="citation" data-cites="savioja_overview_2015">[<a href="#ref-savioja_overview_2015">5</a>]</span>. Also, because the tree is immutable, it can be shared between multiple worker threads, which independently check each branch for valid image sources. The nature of the recursive algorithm makes it a poor fit for an OpenCL implementation, so native (CPU) threads are used instead.</p>
<p>Some paths in the tree may not actually produce valid image sources, and these paths are discarded. For paths which <em>do</em> contribute valid image sources, the propagation delay and frequency-dependent pressure of the image source signal must be found. According to <span class="citation" data-cites="kuttruff_room_2009">[<a href="#ref-kuttruff_room_2009">2</a>, p. 325]</span>, the propagation delay is equal to the distance from the receiver to the image source, divided by the speed of sound. The pressure content is found by convolving together the reflectances of all intermediate surfaces. This is equivalent to a single multiplication per frequency band, as long as reflectances can be represented by real values.</p>
<p>The surface reflectances are found by converting per-band absorptions into per-band normal-incidence reflectance magnitudes by <span class="math inline">\(|R|=\sqrt{1-\alpha}\)</span>. These are converted to per-band impedances by</p>
<ol class="example" type="1">
<li><span class="math display">\[\xi=\frac{1+|R|}{1-|R|}\]</span></li>
</ol>
<p>Finally, the impedances are converted back to <em>angle-dependent</em> reflectances by</p>
<ol start="2" class="example" type="1">
<li><span class="math display">\[R(\theta)=\frac{\xi\cos\theta-1}{\xi\cos\theta+1}\]</span></li>
</ol>
<p>where <span class="math inline">\(\theta\)</span> is the angle of incidence at the surface. This is the same approach taken in <span class="citation" data-cites="southern_room_2013">[<a href="#ref-southern_room_2013">6</a>]</span>.</p>
<p>The contribution <span class="math inline">\(g\)</span> of a single image source with intermediate surfaces <span class="math inline">\(m_1 m_2 \dots m_n\)</span> is given by</p>
<ol start="3" class="example" type="1">
<li><span class="math display">\[g_{m_1 m_2 \dots m_n} = \frac{\sqrt{Z_0/4\pi}}{d_{m_1 m_2 \dots m_n}}
\cdot r_{m_1} \ast r_{m_2} \ast \dots \ast r_{m_n} \ast \delta(\frac{d_{m_1 m_2
\dots m_n}}{c})\]</span></li>
</ol>
<p>where <span class="math inline">\(Z_0\)</span> is the acoustic impedance of air, <span class="math inline">\(c\)</span> is the speed of sound, <span class="math inline">\(d_{m_1 m_2 \dots m_n}\)</span> is the distance from the receiver to the image source, and <span class="math inline">\(r_{m_i}\)</span> is the reflectance of surface <span class="math inline">\(i\)</span>. This assumes that the original source emits a pressure impulse <span class="math inline">\(\delta\)</span> at the starting-time of the simulation. The contributions of all image sources must be summed together to find the final impulse response.</p>
<p>To create a digital audio file representing an impulse response, the output must be discretised at some sampling frequency <span class="math inline">\(f_s\)</span>. The individual image source contributions must be added, at positions corresponding to their propagation delays, into an output buffer at that sampling frequency. The ideal buffer position for a given contribution is equal to <span class="math inline">\(\tau f_s\)</span> where <span class="math inline">\(\tau\)</span> is the propagation delay of that contribution. However, this value is unlikely to be an integer, and so will not coincide with a sample index. The simplest solution would be to round to the closest integer, and use this as the sample index. However, for applications such as multi-microphone simulation which are sensitive to arrival time, this can lead to obvious phase errors. A better solution is suggested in <span class="citation" data-cites="fu_gpu-based_2016">[<a href="#ref-fu_gpu-based_2016">7</a>]</span>: The contribution can be positioned with sub-sample accuracy, by replacing the impulsive <span class="math inline">\(\delta\)</span> signal with the impulse-response of an ideal low-pass filter, with cut-off equal to the output Nyquist frequency. Such an impulse response is infinitely long, but tends to zero quickly, so it can be Hanning windowed to reduce the number of additions required. This form of the impulse is as follows:</p>
<ol start="4" class="example" type="1">
<li><span class="math display">\[
\delta_{\text{LPF}}(n - \epsilon)=
\begin{cases}
\frac{1}{2}(1+\cos\frac{2\pi (n - \epsilon)}{N_w})\text{sinc}(n - \epsilon), &amp; - \frac{N_w}{2} &lt; n &lt; \frac{N_w}{2} \\
0, &amp; \text{otherwise}
\end{cases} 
\]</span></li>
</ol>
<p>where <span class="math inline">\(n\)</span> is an index in the output buffer, <span class="math inline">\(\epsilon\)</span> is the centre of the impulse in samples (<span class="math inline">\(\epsilon=\tau f_s\)</span>), and <span class="math inline">\(N_w\)</span> is the width of the window in samples.</p>
<p>Recall that each image-source contribution has per-band pressure values. Rather than summing all contributions directly to the output buffer, several buffers are created, one per frequency band. The contributions for each band are summed into each buffer individually. The final output of the simulation is created by band-passing and then mixing down the buffers.</p>
<!--

## Testing

TODO compare "exact" method to new method in shoebox model

-->
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-vorlander_auralization:_2007">
<p>[1] M. Vorländer, <em>Auralization: Fundamentals of acoustics, modelling, simulation, algorithms and acoustic virtual reality</em>. Springer Science &amp; Business Media, 2007 [Online]. Available: <a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=CuXF3JkTuhAC&amp;oi=fnd&amp;pg=PA1&amp;dq=auralization+vorlander&amp;ots=EXlinTIK9W&amp;sig=d2t3k2YLLPA1FWvfH15gwlQSi7M" class="uri">https://books.google.com/books?hl=en&amp;lr=&amp;id=CuXF3JkTuhAC&amp;oi=fnd&amp;pg=PA1&amp;dq=auralization+vorlander&amp;ots=EXlinTIK9W&amp;sig=d2t3k2YLLPA1FWvfH15gwlQSi7M</a>. [Accessed: 05-Dec-2016]</p>
</div>
<div id="ref-kuttruff_room_2009">
<p>[2] H. Kuttruff, <em>Room Acoustics, Fifth Edition</em>. CRC Press, 2009. </p>
</div>
<div id="ref-amanatides_fast_1987">
<p>[3] J. Amanatides, A. Woo, and others, “A fast voxel traversal algorithm for ray tracing,” in <em>Eurographics</em>, 1987, vol. 87, pp. 3–10 [Online]. Available: <a href="http://www.cse.chalmers.se/edu/year/2015/course/TDA361/grid.pdf" class="uri">http://www.cse.chalmers.se/edu/year/2015/course/TDA361/grid.pdf</a>. [Accessed: 05-Dec-2016]</p>
</div>
<div id="ref-christensen_new_2005">
<p>[4] C. L. Christensen and J. H. Rindel, “A new scattering method that combines roughness and diffraction effects,” in <em>Forum Acousticum, Budapest, Hungary</em>, 2005 [Online]. Available: <a href="http://www.cs.yorku.ca/course_archive/2005-06/W/6335/feb20/CLC%20fa2005.pdf">http://www.cs.yorku.ca/course_archive/2005-06/W/6335/feb20/CLC%20fa2005.pdf</a>. [Accessed: 05-Dec-2016]</p>
</div>
<div id="ref-savioja_overview_2015">
<p>[5] L. Savioja and U. P. Svensson, “Overview of geometrical room acoustic modeling techniques,” <em>The Journal of the Acoustical Society of America</em>, vol. 138, no. 2, pp. 708–730, 2015 [Online]. Available: <a href="http://scitation.aip.org/content/asa/journal/jasa/138/2/10.1121/1.4926438" class="uri">http://scitation.aip.org/content/asa/journal/jasa/138/2/10.1121/1.4926438</a>. [Accessed: 05-Dec-2016]</p>
</div>
<div id="ref-southern_room_2013">
<p>[6] A. Southern, S. Siltanen, D. T. Murphy, and L. Savioja, “Room impulse response synthesis and validation using a hybrid acoustic model,” <em>IEEE Transactions on Audio, Speech, and Language Processing</em>, vol. 21, no. 9, pp. 1940–1952, 2013 [Online]. Available: <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6516012" class="uri">http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6516012</a>. [Accessed: 05-Dec-2016]</p>
</div>
<div id="ref-fu_gpu-based_2016">
<p>[7] Z.-h. Fu and J.-w. Li, “GPU-based image method for room impulse response calculation,” <em>Multimedia Tools and Applications</em>, pp. 1–17, 2016 [Online]. Available: <a href="http://link.springer.com/article/10.1007/s11042-015-2943-4" class="uri">http://link.springer.com/article/10.1007/s11042-015-2943-4</a>. [Accessed: 05-Dec-2016]</p>
</div>
</div>

        <nav id="prev_next_nav">
    
    
        
    
        
    
        
            
            
            
                <a href="/wayverb/context.html" class="prev_page">Context</a>
            

            
            
            
                <a href="/wayverb/ray_tracer.html" class="next_page">Ray tracer</a>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
</nav>

    </div>
    <footer id="footer" class="wrapper alt">
    <div class="inner">
        <ul class="menu">
			<li>
                &copy; Reuben Thomas 2016. All rights reserved.
            </li>
            <li>
                Design: <a href="http://html5up.net">HTML5 UP</a>, modified by Reuben Thomas.
            </li>
		</ul>
	</div>
</footer>

<!-- Scripts -->
<script src="/wayverb/assets/js/jquery.min.js"></script>
<script src="/wayverb/assets/js/jquery.scrollex.min.js"></script>
<script src="/wayverb/assets/js/jquery.scrolly.min.js"></script>
<script src="/wayverb/assets/js/skel.min.js"></script>
<script src="/wayverb/assets/js/util.js"></script>
<!--[if lte IE 8]><script src="/wayverb/assets/js/ie/respond.min.js"></script><![endif]-->
<script src="/wayverb/assets/js/main.js"></script>

</div>
</body>
</html>
