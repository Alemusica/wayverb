<!DOCTYPE HTML>
<html>
<head>
    <title>Wayverb - Image-source Model</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="/wayverb/assets/favicon.ico" />
	<!--[if lte IE 8]><script src="/wayverb/assets/js/ie/html5shiv.js"></script><![endif]-->
	<link rel="stylesheet" href="/wayverb/assets/css/main.css" />
    <link rel="stylesheet" href="/wayverb/assets/css/font-awesome.min.css" />
	<!--[if lte IE 9]><link rel="stylesheet" href="/wayverb/assets/css/ie9.css" /><![endif]-->
	<!--[if lte IE 8]><link rel="stylesheet" href="/wayverb/assets/css/ie8.css" /><![endif]-->

<!-- Scripts -->
<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
</head>

<body>
<nav id="sidebar_nav">
    <a href="/wayverb/" class="title">Wayverb</a>
    <ul>
        
        
            <li>
                <a href="/wayverb/introduction.html" >
                    Introduction
                </a>
            </li>
        
            <li>
                <a href="/wayverb/context.html" >
                    Context
                </a>
            </li>
        
            <li>
                <a href="/wayverb/theory.html" >
                    Theory
                </a>
            </li>
        
            <li>
                <a href="/wayverb/image_source.html" class="active">
                    Image-source Model
                </a>
            </li>
        
            <li>
                <a href="/wayverb/ray_tracer.html" >
                    Ray tracer
                </a>
            </li>
        
            <li>
                <a href="/wayverb/waveguide.html" >
                    Waveguide
                </a>
            </li>
        
            <li>
                <a href="/wayverb/hybrid.html" >
                    Hybrid Model
                </a>
            </li>
        
            <li>
                <a href="/wayverb/microphone.html" >
                    Microphone modelling
                </a>
            </li>
        
            <li>
                <a href="/wayverb/boundary.html" >
                    Boundary modelling
                </a>
            </li>
        
            <li>
                <a href="/wayverb/evaluation.html" >
                    Evaluation
                </a>
            </li>
        
            <li>
                <a href="/wayverb/conclusion.html" >
                    Conclusion
                </a>
            </li>
        
    </ul>
</nav>

<div id="page_main">
    <header>
        <ul>
            <li class="nav_menu open" >
                <a href="#sidebar_nav">
                    &#9776;
                </a>
            </li>
            <li class="nav_menu close" >
                <a href="#">
                    &#9776;
                </a>
            </li>
            <li>
                <a href="/wayverb/" >
                    Wayverb
                </a>
            </li>
        </ul>
    </header>
    <div class="inner">
        <nav id="prev_next_nav">
    
    
        
    
        
    
        
    
        
            
            
            
                <a href="/wayverb/theory.html" class="prev_page">Theory</a>
            

            
            
            
                <a href="/wayverb/ray_tracer.html" class="next_page">Ray tracer</a>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
</nav>

        <div id="TOC">
<ul>
<li><a href="#image-source-model">Image-source Model</a><ul>
<li><a href="#background">Background</a><ul>
<li><a href="#basic-method">Basic Method</a></li>
<li><a href="#audibility-checking">Audibility Checking</a></li>
<li><a href="#accelerating-the-algorithm">Accelerating the Algorithm</a></li>
</ul></li>
<li><a href="#implementation">Implementation</a></li>
<li><a href="#summary">Summary</a></li>
</ul></li>
<li><a href="#bibliography">References</a></li>
</ul>
</div>
<h1 id="image-source-model" class="major">Image-source Model</h1>
<h2 id="background">Background</h2>
<h3 id="basic-method">Basic Method</h3>
<p>The image-source method aims to find the purely specular reflection paths between a source and a receiver. This process is simplified by assuming that sound propagates only along straight lines or rays. Sound energy travels at a fixed speed, corresponding to the speed of sound, along these rays. The energy in each ray decreases with <span class="math inline">\(1/r^2\)</span>, where <span class="math inline">\(r\)</span> is the total distance that the ray has travelled <span class="citation" data-cites="vorlander_auralization:_2007">[<a href="#ref-vorlander_auralization:_2007">1</a>, p. 58]</span>.</p>
<p>Rays are perfectly reflected at boundaries. When a ray is reflected, it spawns a secondary source “behind” the boundary surface. This source is located on a line perpendicular to the wall, at the same distance from it as the original source, as if the original source has been “mirrored” in the surface (an example is shown in fig. <a href="#fig:image_source_construction">1</a>). This new “image” source now represents a perfect reflection path, in that the distance along the straight line between the receiver and the image source has the same length as the path from the <em>real</em> source to the receiver, reflected in the boundary. If the source is reflected in a single boundary, this represents a first-order reflection. A ray which is reflected from several boundaries is represented by a “higher-order” image-source, which has been mirrored in each of those boundaries in turn <span class="citation" data-cites="kuttruff_room_2009">[<a href="#ref-kuttruff_room_2009">2</a>, p. 104]</span>.</p>
<figure>
<img src="images/image_source_construction.svg" alt="Figure 1: Image sources are found by reflecting the source position in a boundary." id="fig:image_source_construction" /><figcaption>Figure 1: Image sources are found by reflecting the source position in a boundary.</figcaption>
</figure>
<p>All sources, original and image, emit the same impulsive source signal at the same time. The total impulse response (i.e. sound pressure against time) is found by summing the signals from each source, delayed and attenuated appropriately depending on the distance between that source and the receiver, which is equivalent to the length of the specular reflection path. The frequency response of the signal from each image source will additionally be modified depending on the characteristics of each boundary in which that source was reflected.</p>
<p>In the real world, not all energy is perfectly reflected at a boundary. Some energy will be randomly diffused in non-specular directions. The image-source model is not capable of modelling this phenomenon, though this is not particularly problematic. Consider that, once scattered, sound energy cannot become un-scattered. The conversion from incoming energy to scattered energy is unidirectional, so repeated reflections cause the ratio of scattered to specular energy to increase monotonically. Kuttruff shows that, though the earliest reflections may be largely specular, after a few reflections the large majority of sound energy becomes diffuse <span class="citation" data-cites="kuttruff_room_2009">[<a href="#ref-kuttruff_room_2009">2</a>, p. 126]</span>. This suggests that the image model should be used only for very early reflections, where most energy is not scattered, and a secondary model used to compute late, diffuse reflections. In Wayverb, the image model is used for early reflections, and stochastic ray-tracing is used for the diffuse tail. The combination of the two models is described in the <a href="/wayverb/hybrid.html">Hybrid Model</a> section.</p>
<h3 id="audibility-checking">Audibility Checking</h3>
<p>The position of an image source is found by reflecting it in one or more surfaces. Next, it must be checked to ensure it represents a valid specular path to the receiver. This is known as an <em>audibility test</em> <span class="citation" data-cites="vorlander_auralization:_2007">[<a href="#ref-vorlander_auralization:_2007">1</a>, p. 202]</span>.</p>
<p>Consider first a source <span class="math inline">\(S\)</span>, a receiver <span class="math inline">\(R\)</span>, and a single wall <span class="math inline">\(A\)</span>. The source is reflected in <span class="math inline">\(A\)</span>, creating an image-source <span class="math inline">\(S_A\)</span>. A line is constructed from <span class="math inline">\(R\)</span> to <span class="math inline">\(S_A\)</span>. If this line intersects <span class="math inline">\(A\)</span>, then <span class="math inline">\(S_A\)</span> represents a valid image source. Otherwise, there is no possible specular reflection involving <span class="math inline">\(S\)</span>, <span class="math inline">\(R\)</span> and <span class="math inline">\(A\)</span>.</p>
<p>Now consider two walls, <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. The image source <span class="math inline">\(S_{AB}\)</span> has been reflected in <span class="math inline">\(A\)</span> then <span class="math inline">\(B\)</span>. For the image-source to be valid:</p>
<ul>
<li><span class="math inline">\(R \rightarrow S_{AB}\)</span> must intersect <span class="math inline">\(B\)</span> at some point <span class="math inline">\(B_\text{intersection}\)</span>,</li>
<li><span class="math inline">\(B_\text{intersection} \rightarrow S_A\)</span> must intersect <span class="math inline">\(A\)</span> at <span class="math inline">\(A_\text{intersection}\)</span>, <em>and</em></li>
<li><span class="math inline">\(A_\text{intersection} \rightarrow S\)</span> must not intersect with any scene geometry.</li>
</ul>
<p>The validation of a third-order image-source will require three intersection checks, a fourth-order image will require four checks, and so on. This method of tracing backwards from the receiver to each of the image sources is known as <em>backtracking</em>. This process is shown in fig. <a href="#fig:backtracking">2</a>.</p>
<figure>
<img src="images/backtracking.svg" alt="Figure 2: Left: The paths S \rightarrow A \rightarrow R and S \rightarrow A \rightarrow B \rightarrow R are both valid. Right: S \rightarrow B \rightarrow A \rightarrow R is an invalid path because R \rightarrow S_{BA} does not intersect A." id="fig:backtracking" /><figcaption>Figure 2: <strong>Left:</strong> The paths <span class="math inline">\(S \rightarrow A \rightarrow R\)</span> and <span class="math inline">\(S \rightarrow A \rightarrow B \rightarrow R\)</span> are both valid. <strong>Right:</strong> <span class="math inline">\(S \rightarrow B \rightarrow A \rightarrow R\)</span> is an invalid path because <span class="math inline">\(R \rightarrow S_{BA}\)</span> does not intersect <span class="math inline">\(A\)</span>.</figcaption>
</figure>
<p>For a point <span class="math inline">\(p\)</span>, its reflection <span class="math inline">\(p&#39;\)</span> in a plane with unit normal vector <span class="math inline">\(n\)</span> and intersecting the point <span class="math inline">\(t\)</span> can be found by</p>
<p><a name="eq:reflection"></a><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[p&#39; = p - 2n (n \cdot (p - t))\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(1)</span></span> </p>
<p>In eq. <a href="#eq:reflection">1</a>, <span class="math inline">\(\cdot\)</span> is the vector dot operator. This equation can be used to find image source positions. However, in Wayverb surfaces are represented by triangles rather than by infinite planes. The triangle normal vector <span class="math inline">\(n\)</span> is found by taking the cross-product of two of the triangle edge vectors, where an edge vector is the difference between two triangle vertices. The point on the plane <span class="math inline">\(t\)</span> can be set to any of the triangle vertex positions.</p>
<p>To implement backtracking, an algorithm is required for computing the intersection point between a line and a triangle. A description of the ray-triangle intersection method used in Wayverb would be involved, and is omitted here in the interests of brevity. A detailed explanation can be found in <span class="citation" data-cites="moller2005fast">[<a href="#ref-moller2005fast">3</a>]</span>.</p>
<h3 id="accelerating-the-algorithm">Accelerating the Algorithm</h3>
<p>The naive method to find all the image sources for a scene is very expensive: Consider that to find a single first-order image source, the original source must be mirrored in a surface, and then an intersection test must be conducted between that surface and the image-source-to-receiver ray. To find all first-order image sources, this process must be carried out for all surfaces in the scene. To find all second-order image sources, each of those first-order images must be tested against every surface. This continues for higher-order images, so that the number of checks for image sources of a given order is equal to the number of surfaces raised to the power of that order. The relationship between the image-source order and the computation time is therefore exponential, with average-case complexity of <span class="math inline">\(O(N^o)\)</span> where <span class="math inline">\(N\)</span> denotes the number of boundaries, and <span class="math inline">\(o\)</span> is the image-source order. As a result, it is practically impossible to validate all possible image-source positions when the room geometry is complex or the image-source order is high. As an example, imagine that a particular (fictional) simulator might take a second to simulate a scene with 100 surfaces to an image-source depth of 2. If the image source depth is increased to facilitate a longer reverb tail, third-order image sources will take 100 seconds to compute, and fourth-order sources will take 3 hours. Fifth-order sources will take 12 days. Clearly, it is not possible to achieve Wayverb’s efficiency goal of “ten minutes or fewer” under all circumstances using this naive image source technique.</p>
<p>The majority of higher-order image sources found with the naive algorithm will be invalid. That is, they will fail the audibility test. For example, for tenth-order image-sources in a shoebox-shaped room, there are around 1.46e7 different image sources, only 1560 of which are valid <span class="citation" data-cites="kuttruff_room_2009">[<a href="#ref-kuttruff_room_2009">2</a>, p. 323]</span>. If the invalid image-sources can be discarded early, without requiring individual checking, then the amount of computation can be greatly reduced to a viable level. As explained above, image sources above order four or five are rarely required, but even these can be very time-consuming to find with the naive method. Optimisations are, therefore, a necessity for all but the simplest simulations.</p>
<p>To accelerate the image-source process, <span class="citation" data-cites="vorlander_auralization:_2007">[<a href="#ref-vorlander_auralization:_2007">1</a>]</span> suggests tracing a large number of rays in random directions from the source, and logging the unique paths of rays which eventually intersect with the receiver. The complexity of ray tracing grows linearly rather than exponentially with reflection depth, meaning it can find deeper reflections with far fewer operations than the image-source method. Each unique path found in this way is used to generate an image source sequence, which is then checked as normal. This technique has the advantage that the majority of surface sequences are <em>not</em> checked, so the image-source process is fast. However, if the preliminary ray-tracer is not run with enough rays, it is likely to miss some valid paths, especially in complex scenes. Additionally, if the receiver volume is too great, then some invalid paths may still be detected.</p>
<p>The technique used by Wayverb is similar to that presented in <span class="citation" data-cites="vorlander_auralization:_2007">[<a href="#ref-vorlander_auralization:_2007">1</a>]</span>, but makes a small change to the acceleration process. Note that this does not affect the physical interpretation of the image-source model. It simply changes the way in which ray paths are initially selected for further audibility checking.</p>
<p>A large number of random rays are traced, as before, but at each reflection point, the receiver is checked to see whether it is visible. If it is, then the surface sequence is checked for a valid image-source. This adds constant work per-reflection to the ray-tracing process, which is insignificant in terms of overall time-complexity. This technique has two main advantages. Firstly, more paths are checked, so it is more likely to find all the valid image-sources. Instead of just checking ray paths which intersect the receiver, this method checks all paths which are <em>capable</em> of intersecting the receiver. Secondly, initial ray paths don’t have to be specular, so techniques like <em>vector-based scattering</em> can be used. The disadvantage is that a greater number of validity checks are required, though this number is still many times smaller than would be required by a naive implementation.</p>
<h2 id="implementation">Implementation</h2>
<p>Here the concrete implementation of the image-source method is presented, as it is used in Wayverb. Figure <a href="#fig:image_source_process">3</a> gives an overview of the entire process.</p>
<figure>
<img src="images/image_source_process.svg" alt="Figure 3: Creation of an impulse response using image sources." id="fig:image_source_process" /><figcaption>Figure 3: Creation of an impulse response using image sources.</figcaption>
</figure>
<!--
The simulation prerequisites are:

* source position 
* receiver position 
* speed of sound in air 
* acoustic impedance of air 
* a scene, made up of triangles, where each triangle has an associated material
  comprised of multiband absorption and scattering coefficients (note that 
  curved surfaces are not supported, and must be approximated by small 
  triangles)
-->
<p>The main prerequisite for the simulation is a scene, made up of triangles, where each triangle has an associated material comprised of multi-band absorption coefficients. First, an axis-aligned bounding box is computed for this scene, and split into uniformly sized cuboid <em>voxels</em>. Each voxel holds a reference to any triangles in the scene which happen to intersect with that voxel. The voxel mesh acts as an “acceleration structure”, speeding up intersection tests between rays and triangles. To check for an intersection between a ray and a number of triangles, the simplest method is to check the ray against each triangle individually, which is very time consuming. The voxel mesh allows the number of checks to be greatly reduced, by checking only triangles that are within voxels that the ray intersects. These voxels can be found very quickly, by “walking” the voxels along the ray, using an algorithm presented by Amanatides, Woo et al. <span class="citation" data-cites="amanatides_fast_1987">[<a href="#ref-amanatides_fast_1987">4</a>]</span>. For large scenes with many triangles, this method can lead to speed-ups of an order of magnitude or more. All ray-intersection tests mentioned throughout this thesis use the voxel-acceleration method, unless explicitly noted. In particular, both the initial ray-casting <em>and</em> the image-source audibility-checking are accelerated using the voxel method.</p>
<p>Rays are fired in uniform random directions from the source (item 1 in the figure). Each ray is checked for an intersection with the scene, and if an intersection is found, some data about the intersection is recorded. Specifically, the record includes the triangle which was intersected, and whether or not the receiver is visible from the intersection point. Then, the vector-based scattering method <span class="citation" data-cites="christensen_new_2005">[<a href="#ref-christensen_new_2005">5</a>]</span> (see the <a href="/wayverb/ray_tracer.html">Ray Tracing</a> section for details on this) is used to find the directions of new rays, which are fired from the intersection points. The ray-tracing process continues up to a certain depth, which is artificially limited to ten reflections in Wayverb. For most simulations, three or four reflections should be adequate, though this depends somewhat on the scattering coefficients of the surfaces. After a few reflections, most sound energy is diffuse rather than specular, and other methods are better suited to modelling this scattering, as explained in the <a href="#basic-method">Basic Method</a> subsection above.</p>
<p>The ray tracer produces a list of reflection paths for each ray, where a single reflection path is defined by a sequence of visited surfaces (item 2 in the figure). Some rays may follow the same paths (reflect from the same surfaces), and so duplicate paths must be removed. This is achieved by condensing per-ray information into a tree of valid paths (item 3). Each node in the tree stores a reference to a triangle in the scene, and whether or not the receiver is visible from this triangle. Each unique path starting from a root node in the tree represents a possible image source contribution, which must be checked. This checking is carried out using the backtracking method explained above (item 4). The tree structure can be traversed using depth-first recursion, allowing the results of some intermediate calculations to be cached between ray paths, speeding up the calculation with only minimal memory overhead. This is similar to the approach mentioned in <span class="citation" data-cites="savioja_overview_2015">[<a href="#ref-savioja_overview_2015">6</a>]</span>. Also, because the tree is immutable, it can be shared between multiple worker threads, which independently check each branch for valid image sources. The nature of the recursive algorithm makes it a poor fit for an OpenCL implementation, so native (CPU) threads are used instead.</p>
<p>Some paths in the tree may not actually produce valid image sources, and these paths are discarded (item 5). For paths which <em>do</em> contribute valid image sources, the propagation delay and frequency-dependent pressure of the image source signal must be found. As described by Kuttruff, the propagation delay is equal to the distance from the receiver to the image source, divided by the speed of sound, <span class="citation" data-cites="kuttruff_room_2009">[<a href="#ref-kuttruff_room_2009">2</a>, p. 325]</span>. The pressure content is found by convolving together the reflectances of all intermediate surfaces. This is equivalent to a single multiplication per frequency band, as long as the reflectance value for each band per surface can be represented by a single real value.</p>
<p>The surface reflectances are found by converting per-band absorptions into per-band normal-incidence reflectance magnitudes using</p>
<p><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[|R|=\sqrt{1-\alpha}\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(2)</span></span> </p>
<p>where <span class="math inline">\(R\)</span> is the surface reflectance, and <span class="math inline">\(\alpha\)</span> is the absorption coefficient of that frequency band. This equation is simply a rearrangement of +<strong>???</strong>. These per-band reflectances are converted to per-band normal-incidence impedances using +<strong>???</strong>. Finally, the impedances are converted back to <em>angle-dependent</em> reflectances by +<strong>???</strong>. This is the same approach taken in <span class="citation" data-cites="southern_room_2013">[<a href="#ref-southern_room_2013">7</a>]</span>. The angle of incidence must be found for each individual reflection, by taking the inverse cosine of the dot product between the incident ray direction and the surface normal, when both are unit vectors.</p>
<p>The contribution <span class="math inline">\(g\)</span> of a single image source with intermediate surfaces <span class="math inline">\(m_1 m_2 \dots m_n\)</span> is given by</p>
<p><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[g_{m_1 m_2 \dots m_n} = \frac{\sqrt{Z_0/4\pi}}{d_{m_1 m_2 \dots m_n}}
\cdot R_{m_1} \ast R_{m_2} \ast \dots \ast R_{m_n} \ast \delta(\frac{d_{m_1 m_2
\dots m_n}}{c})\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(3)</span></span> </p>
<p>where <span class="math inline">\(Z_0\)</span> is the acoustic impedance of air, <span class="math inline">\(c\)</span> is the speed of sound, <span class="math inline">\(d_{m_1 m_2 \dots m_n}\)</span> is the distance from the receiver to the image source, and <span class="math inline">\(R_{m_i}\)</span> is the reflectance of surface <span class="math inline">\(i\)</span>. This assumes that the original source emits a pressure impulse <span class="math inline">\(\delta\)</span> at the starting-time of the simulation. The contributions of all image sources must be summed together to find the final impulse response.</p>
<p>To create a digital audio file representing an impulse response, the output must be discretised at some sampling frequency <span class="math inline">\(f_s\)</span>. The individual image source contributions must be added, at positions corresponding to their propagation delays, into an output buffer at that sampling frequency. The ideal buffer position for a given contribution is equal to <span class="math inline">\(\tau f_s\)</span> where <span class="math inline">\(\tau\)</span> is the propagation delay of that contribution, equal to the total ray distance divided by the speed of sound. However, this value is unlikely to be an integer, and so may not coincide with a sample index. The simplest solution would be to round to the closest integer, and use this as the sample index. However, for applications such as multi-microphone simulation which are sensitive to arrival time, this can lead to phase errors. A better solution is suggested by Fu and Li <span class="citation" data-cites="fu_gpu-based_2016">[<a href="#ref-fu_gpu-based_2016">8</a>]</span>: The contribution can be positioned with sub-sample accuracy, by replacing the impulsive <span class="math inline">\(\delta\)</span> signal with the impulse-response of an ideal low-pass filter, with cut-off equal to the output Nyquist frequency. Such an impulse response is infinitely long, but tends to zero quickly, so a Hann window can be applied to limit its length. This form of the impulse is as follows:</p>
<p><span style="display: inline-block; position: relative; width: 100%"><span class="math display">\[
\delta_{\text{LPF}}(n - \epsilon)=
\begin{cases}
    \frac{1}{2}(1+\cos\frac{2\pi (n - \epsilon)}{N_w})\text{sinc}(n - \epsilon), &amp; - \frac{N_w}{2} &lt; n &lt; \frac{N_w}{2} \\
    0, &amp; \text{otherwise}
\end{cases} 
\]</span><span style="position: absolute; right: 0em; top: 50%; line-height:0; text-align: right">(4)</span></span> </p>
<p>where <span class="math inline">\(n\)</span> is an index in the output buffer, <span class="math inline">\(\epsilon\)</span> is the centre of the impulse in samples (<span class="math inline">\(\epsilon=\tau f_s\)</span>), and <span class="math inline">\(N_w\)</span> is the width of the window in samples.</p>
<p>Each image-source contribution has per-band pressure values. Rather than summing all contributions directly to the output buffer, several buffers are created, one per frequency band. The contributions for each band are summed into each buffer individually (item 6 in the figure). The final output of the simulation is created by band-passing and then mixing down the buffers (item 7). A single method for multi-band filtering is used throughout Wayverb, and more details are given in the <a href="/wayverb/ray_tracer.html">Ray Tracer</a> section.</p>
<h2 id="summary">Summary</h2>
<p>The image source model can be used to find the path lengths and pressures of purely specular reflections. It cannot model diffuse reflections, and late reflections are generally diffuse. Therefore, the image source model is only suitable for predicting early reflections. The naive implementation of the image source model has exponential complexity, and a great deal of the computations are redundant. For this reason, a ray-tracing-based implementation with greatly improved complexity has been developed. This implementation is more efficient than the naive implementation (i.e. it does less redundant work) although it may fail to find some valid image sources if the number of rays is too low. This has been deemed a reasonable trade-off. The implementation is also designed to re-use ray paths found by the ray-tracer model, minimising duplicated work between the two models. Finally, implementation details such as a method for frequency-dependent boundary modelling, and sub-sample-accurate impulse placement, have been described.</p>
<h1 id="bibliography" class="unnumbered">References</h1>
<div id="refs" class="references">
<div id="ref-vorlander_auralization:_2007">
<p>[1] M. Vorländer, <em>Auralization: Fundamentals of acoustics, modelling, simulation, algorithms and acoustic virtual reality</em>. Springer Science &amp; Business Media, 2007. </p>
</div>
<div id="ref-kuttruff_room_2009">
<p>[2] H. Kuttruff, <em>Room Acoustics, Fifth Edition</em>. CRC Press, 2009. </p>
</div>
<div id="ref-moller2005fast">
<p>[3] T. Möller and B. Trumbore, “Fast, minimum storage ray/triangle intersection,” in <em>ACM SIGGRAPH 2005 courses</em>, 2005, p. 7. </p>
</div>
<div id="ref-amanatides_fast_1987">
<p>[4] J. Amanatides, A. Woo, and others, “A fast voxel traversal algorithm for ray tracing,” in <em>Eurographics</em>, 1987, vol. 87, pp. 3–10. </p>
</div>
<div id="ref-christensen_new_2005">
<p>[5] C. L. Christensen and J. H. Rindel, “A new scattering method that combines roughness and diffraction effects,” in <em>Forum Acousticum, Budapest, Hungary</em>, 2005. </p>
</div>
<div id="ref-savioja_overview_2015">
<p>[6] L. Savioja and U. P. Svensson, “Overview of geometrical room acoustic modeling techniques,” <em>The Journal of the Acoustical Society of America</em>, vol. 138, no. 2, pp. 708–730, 2015. </p>
</div>
<div id="ref-southern_room_2013">
<p>[7] A. Southern, S. Siltanen, D. T. Murphy, and L. Savioja, “Room impulse response synthesis and validation using a hybrid acoustic model,” <em>IEEE Transactions on Audio, Speech, and Language Processing</em>, vol. 21, no. 9, pp. 1940–1952, 2013. </p>
</div>
<div id="ref-fu_gpu-based_2016">
<p>[8] Z.-h. Fu and J.-w. Li, “GPU-based image method for room impulse response calculation,” <em>Multimedia Tools and Applications</em>, pp. 1–17, 2016. </p>
</div>
</div>

        <nav id="prev_next_nav">
    
    
        
    
        
    
        
    
        
            
            
            
                <a href="/wayverb/theory.html" class="prev_page">Theory</a>
            

            
            
            
                <a href="/wayverb/ray_tracer.html" class="next_page">Ray tracer</a>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
</nav>

    </div>
    <footer id="footer" class="wrapper alt">
    <div class="inner">
        <ul class="menu">
			<li>
                &copy; Reuben Thomas 2016. All rights reserved.
            </li>
            <li>
                Design: <a href="http://html5up.net">HTML5 UP</a>, modified by Reuben Thomas.
            </li>
		</ul>
	</div>
</footer>

<!-- Scripts -->
<script src="/wayverb/assets/js/jquery.min.js"></script>
<script src="/wayverb/assets/js/jquery.scrollex.min.js"></script>
<script src="/wayverb/assets/js/jquery.scrolly.min.js"></script>
<script src="/wayverb/assets/js/skel.min.js"></script>
<script src="/wayverb/assets/js/util.js"></script>
<!--[if lte IE 8]><script src="/wayverb/assets/js/ie/respond.min.js"></script><![endif]-->
<script src="/wayverb/assets/js/main.js"></script>

</div>
</body>
</html>
